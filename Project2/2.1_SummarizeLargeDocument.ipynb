{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assignment 1\n",
    "\n",
    "# Summarization of large document \n",
    "\n",
    "* Data source: Arxiv papers for math/AI/physics (5 papers each)\n",
    "\n",
    "* File path: '../data_source/arxiv.org/...'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Data Preparation\n",
    "\n",
    "* Form Recognizer - analyze PDF file, page contents are returned.\n",
    "\n",
    "* Save the page contents into JSON file for later processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read PDF file using form recognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.formrecognizer import DocumentAnalysisClient\n",
    "# import os\n",
    "# from dotenv import load_dotenv\n",
    "# load_dotenv()\n",
    "document_analysis_client = DocumentAnalysisClient(\n",
    "    endpoint=os.environ[\"AZURE_FORM_RECOGNIZER_ENDPOINT\"], \n",
    "    credential=AzureKeyCredential(os.environ[\"AZURE_FORM_RECOGNIZER_KEY\"]))\n",
    "\n",
    "# pdf_file = './data_source/arxiv.org/AI/2311.05227.pdf'\n",
    "pdf_file = './data_source/arxiv.org/math/2303.17103.pdf'\n",
    "with open(pdf_file, \"rb\") as f:\n",
    "    poller = document_analysis_client.begin_analyze_document(\n",
    "        \"prebuilt-read\", document=f\n",
    "    )\n",
    "    # not_completed=False\n",
    "result = poller.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result.pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Put page contents into json structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_content = []\n",
    "for page in result.pages:\n",
    "    all_lines_content = []\n",
    "    for line_idx, line in enumerate(page.lines):\n",
    "        all_lines_content.append(' '.join([word.content for word in line.get_words()]))\n",
    "    page_content.append({'filename': pdf_file,\n",
    "        'page_number':page.page_number, \n",
    "        'page_content':' '.join(all_lines_content)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write to a JSON file so that we can summarize it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON data has been saved to ./data_source/arxiv.org/math/2303.17103.pdf_output.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Save JSON data into a file so that we donot need to call form recongnizer again\n",
    "# Specify the output file path\n",
    "output_file_path = pdf_file + '_output.json'\n",
    "\n",
    "# Save the JSON data to a file\n",
    "with open(output_file_path, 'w') as json_file:\n",
    "    json.dump(page_content, json_file, indent=4)\n",
    "\n",
    "print(f\"JSON data has been saved to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Document Summarization\n",
    "\n",
    "* Read documnet (previously processed JSON file)\n",
    "\n",
    "* Use Azure OpenAI 'completion' to summarize the document. \n",
    "\n",
    "* Summary (append): summarize first page, then summarize: 1st page summary + 2nd page contents, then previous summary + 3rd page content, ... till all pages are done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use Azure OpenAI 'Completion' to summarize content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: The openai-python library support for Azure OpenAI is in preview. \n",
    "# This version is not supported in ChatCompletion.\n",
    "# import os\n",
    "import openai\n",
    "\n",
    "openai.api_type = \"azure\"\n",
    "# openai.api_version = \"2023-07-01-preview\"\n",
    "openai.api_version = \"2023-09-15-preview\"\n",
    "API_KEY = os.getenv(\"OPENAI_API_KEY\",\"\").strip()\n",
    "assert API_KEY, \"ERROR: Azure OpenAI Key is missing\"\n",
    "openai.api_key = API_KEY\n",
    "RESOURCE_ENDPOINT = os.getenv(\"OPENAI_API_ENDPOINT\",\"\").strip()\n",
    "assert RESOURCE_ENDPOINT, \"ERROR: Azure OpenAI Endpoint is missing\"\n",
    "assert \"openai.azure.com\" in RESOURCE_ENDPOINT.lower(), \"ERROR: Azure OpenAI Endpoint should be in the form: \\n\\n\\t<your unique endpoint identifier>.openai.azure.com\"\n",
    "openai.api_base = RESOURCE_ENDPOINT\n",
    "\n",
    "COMPLETIONS_MODEL = os.getenv('DEPLOYMENT_NAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try different prompts ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def openai_completion_summarization(previous_summary, new_content):\n",
    "    # Construct prompt\n",
    "    # prompt_text = (\n",
    "    #     'Provide a summary of the contents below. Note that your summary should consider:\\n'\n",
    "    #     'Summary based on previous content:\\n ' +\n",
    "    #     previous_summary + ' \\n' +\n",
    "    #     'and the new content: \\n' + \n",
    "    #     new_content\n",
    "    # )\n",
    "\n",
    "    prompt_text = 'Provide a summary of the contents below.\\n' + \\\n",
    "        previous_summary + ' \\n ' + new_content    \n",
    "\n",
    "    # prompt_text = 'Provide a summary of the text below that captures its main idea.\\n\\n' + \\\n",
    "    #     previous_summary + ' \\n ' + new_content\n",
    "    \n",
    "    debug = False\n",
    "    if debug: print(\"prompt_text:\", prompt_text)\n",
    "\n",
    "    response = openai.Completion.create(\n",
    "        engine=COMPLETIONS_MODEL,\n",
    "        prompt=prompt_text,\n",
    "        temperature=0,\n",
    "        max_tokens=2000,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        best_of=1,\n",
    "        stop=None)\n",
    "\n",
    "    if debug: print(f\"\\nOpenAI completion summary: [{repr(response['choices'][0]['text'])}]\")\n",
    "    return response['choices'][0]['text']\n",
    "\n",
    "# previous_summary = ''\n",
    "# new_content = \"At Microsoft, we have been on a quest to advance AI beyond existing techniques, by taking a more holistic, human-centric approach to learning and understanding. As Chief Technology Officer of Azure AI Services, I have been working with a team of amazing scientists and engineers to turn this quest into a reality. In my role, I enjoy a unique perspective in viewing the relationship among three attributes of human cognition: monolingual text (X), audio or visual sensory signals, (Y) and multilingual (Z). At the intersection of all three, there’s magic—what we call XYZ-code as illustrated in Figure 1—a joint representation to create more powerful AI that can speak, hear, see, and understand humans better. We believe XYZ-code will enable us to fulfill our long-term vision: cross-domain transfer learning, spanning modalities and languages. The goal is to have pre-trained models that can jointly learn representations to support a broad range of downstream AI tasks, much in the way humans do today. Over the past five years, we have achieved human performance on benchmarks in conversational speech recognition, machine translation, conversational question answering, machine reading comprehension, and image captioning. These five breakthroughs provided us with strong signals toward our more ambitious aspiration to produce a leap in AI capabilities, achieving multi-sensory and multilingual learning that is closer in line with how humans learn and understand. I believe the joint XYZ-code is a foundational component of this aspiration, if grounded with external knowledge sources in the downstream AI tasks.\"\n",
    "# result = openai_completion_summarization(previous_summary, new_content)\n",
    "# print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read the output JSON file and do summarization using summary append approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def load_page_content_from_json_file(json_file_path):\n",
    "    with open(json_file_path, 'r') as file:\n",
    "        json_data = json.load(file)\n",
    "    return json_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the paper in reversed order seems better since most likely the reference pages are at the end of the article, the most likely the import semantics are at the beginning of the article. Actually we could use the Custom Classification Model to find the 'content page' and use that to guide the summarization on content pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "# Specify the JSON file path\n",
    "# json_file_path = './data_source/arxiv.org/AI/2311.05227.pdf_output.json'\n",
    "json_file_path = './data_source/arxiv.org/math/2303.17103.pdf_output.json'\n",
    "\n",
    "# Call the function to print page content from the JSON file\n",
    "page_content_in_json = load_page_content_from_json_file(json_file_path)\n",
    "\n",
    "debug = False\n",
    "\n",
    "# Loop through the JSON and print page_content\n",
    "previous_summary_text = 'None'\n",
    "for page in reversed(page_content_in_json):\n",
    "    new_page_number = page.get('page_number', '')\n",
    "    new_page_content = page.get('page_content', '')\n",
    "    if debug:\n",
    "        print(\"Page number: \", new_page_number)\n",
    "\n",
    "    # print(\"Page content: \", new_page_content)\n",
    "    summary_result = openai_completion_summarization(previous_summary_text, new_page_content)\n",
    "    previous_summary_text = summary_result.split('\\n\\n', 1)[-1]\n",
    "    # time.sleep(2)\n",
    "    if debug:\n",
    "        print(\"Summary: \", previous_summary_text)\n",
    "        print(\"=\" * 50)  # Separating page contents for better readability\n",
    "\n",
    "final_summary = [{\"File name\": json_file_path,\n",
    "                  \"Summary\": previous_summary_text}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'File name': './data_source/arxiv.org/math/2303.17103.pdf_output.json',\n",
       "  'Summary': 'The article discusses the correlation between UFO sightings and meteor showers, and the use of scientific tools and data analysis in researching this topic. It also explores the intersection of science and popular culture in the study of UFO sightings and meteor showers. The article includes a graph showing the distribution of UFO sightings by year and a map showing the concentration of sightings during meteor showers in different regions of the world. It also mentions the use of parameters such as shape and duration in studying UFO sightings and discusses the occurrence of \"balloon\" incidents in February 2023. The article concludes by summarizing the methods used in the study, including the analysis of over 80,000 UFO sightings and their correlation with reports of high-altitude balloons and meteor showers. The study suggests that there may be a transport pipeline for alien craft from interplanetary and possibly interstellar space to the Earth\\'s surface, using meteor showers as a distraction. The article also mentions the historical connection between UFO sightings and lighter-than-air objects, such as the famous Roswell incident. Overall, the article highlights the need for further research and understanding of UFO sightings and their potential connection to extraterrestrial objects.'}]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save final summary in json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON data has been saved to ./data_source/arxiv.org/math/2303.17103.pdf_summary.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Save JSON data into a file so that we donot need to call form recongnizer again\n",
    "# Specify the output file path\n",
    "# Find the position of '_output'\n",
    "output_index = json_file_path.find('_output')\n",
    "\n",
    "# Extract the substring before '_output'\n",
    "summary_file_path = json_file_path[:output_index] + '_summary.json'\n",
    "\n",
    "# Save the JSON data to a file\n",
    "with open(summary_file_path, 'w') as json_file:\n",
    "    json.dump(final_summary, json_file, indent=4)\n",
    "\n",
    "print(f\"JSON data has been saved to {summary_file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
