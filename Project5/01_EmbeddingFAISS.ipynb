{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process data and save them in vector store\n",
    "\n",
    "# Embedding and vector store\n",
    "\n",
    "* Data source: SEC filing reports\n",
    "\n",
    "* Azure OpenAI - embedding\n",
    "\n",
    "* FAISS\n",
    "\n",
    "* Azure AI Search (Azure Cognitive Searc) - vector store and vector search, semantic search, or both\n",
    "\n",
    "* LangChain framework - Azure OpenAI, Azure AI Search\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure OpenAI Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "# Set up Azure OpenAI\n",
    "load_dotenv()\n",
    "\n",
    "openai.api_type = \"azure\"\n",
    "\n",
    "AZURE_OPENAI_API_VERSION = os.getenv(\"AAG_AZURE_OPENAI_API_VERSION\")\n",
    "openai.api_version = AZURE_OPENAI_API_VERSION\n",
    "\n",
    "AZURE_OPENAI_API_KEY = os.getenv(\"AAG_AZURE_OPENAI_API_KEY\").strip()\n",
    "assert AZURE_OPENAI_API_KEY, \"ERROR: Azure OpenAI Key is missing\"\n",
    "openai.api_key = AZURE_OPENAI_API_KEY\n",
    "\n",
    "AZURE_OPENAI_ENDPOINT = os.getenv(\"AAG_AZURE_OPENAI_ENDPOINT\",\"\").strip()\n",
    "assert AZURE_OPENAI_ENDPOINT, \"ERROR: Azure OpenAI Endpoint is missing\"\n",
    "openai.api_base = AZURE_OPENAI_ENDPOINT\n",
    "\n",
    "# Deployment for Chat\n",
    "# DEPLOYMENT_NAME_CHAT = os.getenv('DEPLOYMENT_NAME_CHAT')\n",
    "DEPLOYMENT_NAME_CHAT = os.getenv('AAG_DEPLOYMENT_NAME_CHAT_16K')\n",
    "\n",
    "# Deployment for embedding\n",
    "DEPLOYMENT_NAME_EMBEDDING = os.getenv(\"AAG_DEPLOYMENT_NAME_EMBEDDING\")\n",
    "model: str = DEPLOYMENT_NAME_EMBEDDING\n",
    "\n",
    "# Azure AI Search (Cognitive vector store)\n",
    "vector_store_address: str = os.getenv(\"AAG_AZURE_SEARCH_SERVICE_ENDPOINT\")  \n",
    "vector_store_password: str = os.getenv(\"AAG_AZURE_SEARCH_ADMIN_KEY\")\n",
    "# index_name: str = \"langchain-vector-arxiv-physics\"\n",
    "\n",
    "# Deployment for embedding\n",
    "BING_SUBSCRIPTION_KEY = os.getenv(\"BING_SUBSCRIPTION_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load travel itinerary\n",
    "\n",
    "* Parking, Flight, Car Rental, Hotel ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load pdf files in a dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFDirectoryLoader\n",
    "\n",
    "loader = PyPDFDirectoryLoader(\"./data_source/\")\n",
    "\n",
    "loaded_documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "# Split documents to chucks\n",
    "text_splitter = CharacterTextSplitter(chunk_size=2000, chunk_overlap=0)\n",
    "splitted_docs = text_splitter.split_documents(loaded_documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitted_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create embeddings and vector store instances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FAISS vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "# Get Azure OpenAI embedding\n",
    "embeddings: OpenAIEmbeddings = OpenAIEmbeddings(\n",
    "    deployment=model,\n",
    "    model=model,\n",
    "    chunk_size=1,   # this 'chunk_size' is misleading, it is really about 'input' text string, not the number of words or characters in the text.\n",
    "    openai_api_base=AZURE_OPENAI_ENDPOINT,\n",
    "    openai_api_type=\"azure\",\n",
    "    api_key=AZURE_OPENAI_API_KEY,\n",
    ")\n",
    "\n",
    "# Create the vector index\n",
    "db = FAISS.from_documents(splitted_docs, embeddings)\n",
    "# Query the index\n",
    "query = \"What does the travel starts? Which terminal is it?\"\n",
    "docs = db.similarity_search(query)\n",
    "# Print the results\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Travel\n",
    "db.save_local(\"faiss_index_travel\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
