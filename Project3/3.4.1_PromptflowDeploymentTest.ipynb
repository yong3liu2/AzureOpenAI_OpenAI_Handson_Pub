{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use deployed prompt flow endpoint, in this case it is a Bing search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import json\n",
    "import os\n",
    "import ssl\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "# Set up Azure OpenAI\n",
    "load_dotenv()\n",
    "\n",
    "AAG_PROMPT_FLOW_ENDPOINT_BING_SEARCH = os.getenv(\"AAG_PROMPT_FLOW_ENDPOINT_BING_SEARCH\",\"\").strip()\n",
    "# Replace this with the primary/secondary key or AMLToken for the endpoint\n",
    "AAG_PROMPT_FLOW_ENDPOINT_BING_SEARCH_KEY = os.getenv(\"AAG_PROMPT_FLOW_ENDPOINT_BING_SEARCH_KEY\",\"\").strip()\n",
    " \n",
    "def allowSelfSignedHttps(allowed):\n",
    "    # bypass the server certificate verification on client side\n",
    "    if allowed and not os.environ.get('PYTHONHTTPSVERIFY', '') and getattr(ssl, '_create_unverified_context', None):\n",
    "        ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "allowSelfSignedHttps(True) # this line is needed if you use self-signed certificate in your scoring service.\n",
    "\n",
    "def bing_search_endpoint(user_question):\n",
    "    # Request data goes here\n",
    "    # The example below assumes JSON formatting which may be updated\n",
    "    # depending on the format your endpoint expects.\n",
    "    # More information can be found here:\n",
    "    # https://docs.microsoft.com/azure/machine-learning/how-to-deploy-advanced-entry-script\n",
    "    data = {\"question\": user_question}\n",
    "    # data = {\"questiont\":\"Sam Altman join Microsoft and return back to OpenAI as of 11/22/2023?\"}\n",
    "    # data = {\"question\":\"Who is China's president as of 11/22/2023?\"}\n",
    "\n",
    "    body = str.encode(json.dumps(data))\n",
    "\n",
    "    url = AAG_PROMPT_FLOW_ENDPOINT_BING_SEARCH\n",
    "    # Replace this with the primary/secondary key or AMLToken for the endpoint\n",
    "    api_key = AAG_PROMPT_FLOW_ENDPOINT_BING_SEARCH_KEY\n",
    "    if not api_key:\n",
    "        raise Exception(\"A key should be provided to invoke the endpoint\")\n",
    "\n",
    "    # The azureml-model-deployment header will force the request to go to a specific deployment.\n",
    "    # Remove this header to have the request observe the endpoint traffic rules\n",
    "    headers = {'Content-Type':'application/json', 'Authorization':('Bearer '+ api_key), 'azureml-model-deployment': 'yongpfbingsearchlangchain' }\n",
    "\n",
    "    req = urllib.request.Request(url, body, headers)\n",
    "\n",
    "    try:\n",
    "        response = urllib.request.urlopen(req)\n",
    "\n",
    "        result = response.read()\n",
    "        # print(result)\n",
    "        return result\n",
    "    except urllib.error.HTTPError as error:\n",
    "        print(\"The request failed with status code: \" + str(error.code))\n",
    "\n",
    "        # Print the headers - they include the requert ID and the timestamp, which are useful for debugging the failure\n",
    "        print(error.info())\n",
    "        print(error.read().decode(\"utf8\", 'ignore'))\n",
    "\n",
    "# result = bing_search_endpoint(\"Who is China's president as of 11/22/2023?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup Azure OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "# Set up Azure OpenAI\n",
    "load_dotenv()\n",
    "\n",
    "openai.api_type = \"azure\"\n",
    "\n",
    "AZURE_OPENAI_API_VERSION = os.getenv(\"AAG_AZURE_OPENAI_API_VERSION\")\n",
    "openai.api_version = AZURE_OPENAI_API_VERSION\n",
    "\n",
    "AZURE_OPENAI_API_KEY = os.getenv(\"AAG_AZURE_OPENAI_API_KEY\").strip()\n",
    "assert AZURE_OPENAI_API_KEY, \"ERROR: Azure OpenAI Key is missing\"\n",
    "openai.api_key = AZURE_OPENAI_API_KEY\n",
    "\n",
    "AZURE_OPENAI_ENDPOINT = os.getenv(\"AAG_AZURE_OPENAI_ENDPOINT\",\"\").strip()\n",
    "assert AZURE_OPENAI_ENDPOINT, \"ERROR: Azure OpenAI Endpoint is missing\"\n",
    "openai.api_base = AZURE_OPENAI_ENDPOINT\n",
    "\n",
    "# Deployment for Chat\n",
    "# DEPLOYMENT_NAME_CHAT = os.getenv('DEPLOYMENT_NAME_CHAT')\n",
    "DEPLOYMENT_NAME_CHAT = os.getenv('AAG_DEPLOYMENT_NAME_CHAT_16K')\n",
    "\n",
    "# Deployment for embedding\n",
    "DEPLOYMENT_NAME_EMBEDDING = os.getenv(\"AAG_DEPLOYMENT_NAME_EMBEDDING\")\n",
    "model: str = DEPLOYMENT_NAME_EMBEDDING\n",
    "\n",
    "# Deployment for embedding\n",
    "BING_SUBSCRIPTION_KEY = os.getenv(\"BING_SUBSCRIPTION_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.docstore.document import Document\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "\n",
    "# Construct Azure OpenAI\n",
    "llm = AzureChatOpenAI(\n",
    "    openai_api_type = \"azure\",\n",
    "    api_version = AZURE_OPENAI_API_VERSION,\n",
    "    azure_endpoint = AZURE_OPENAI_ENDPOINT,    \n",
    "    api_key = AZURE_OPENAI_API_KEY,\n",
    "    azure_deployment = DEPLOYMENT_NAME_CHAT,\n",
    "    temperature=0)\n",
    "\n",
    "def generate_response(txt):\n",
    "    # Split text\n",
    "    text_splitter = CharacterTextSplitter()\n",
    "    texts = text_splitter.split_text(txt)\n",
    "    # Create multiple documents\n",
    "    docs = [Document(page_content=t) for t in texts]\n",
    "    # Text summarization\n",
    "    chain = load_summarize_chain(llm, chain_type='stuff')\n",
    "    return chain.run(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main Bot loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start chatting with the bot ('quit' to exit):\n",
      "Me: Who is China's president as of 11/22/2023?\n",
      "Bot: Chinese President Xi Jinping has arrived in the United States for his first visit in six years. US President Joe Biden aims to have productive bilateral talks with Xi Jinping. The two leaders previously met at the Asia-Pacific Economic Cooperation summit in Woodside, California. Xi Jinping also met with executives in San Francisco. The 2023 Chinese presidential election was held on March 10, 2023, where Xi Jinping was re-elected as President.\n",
      "Me: Sam Altman join Microsoft and return back to OpenAI as of 11/23/2023?\n",
      "Bot: Sam Altman has returned as CEO of OpenAI just days after being ousted from the position. This follows an employee backlash and turmoil within the company. Microsoft has invested $13 billion into OpenAI and Altman is also joining Microsoft. Emmett Shear has been named interim CEO of OpenAI. Talks are ongoing about the future of the company.\n",
      "Me: quit\n",
      "Exiting conversation.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def chat_with_bot():\n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        print(\"Me:\", user_input)\n",
    "        if user_input.lower() == 'quit':\n",
    "            print(\"Exiting conversation.\")\n",
    "            break\n",
    "\n",
    "        response_bytes = bing_search_endpoint(user_input)\n",
    "\n",
    "        # Decode the bytes-like object to a string using UTF-8 encoding\n",
    "        response_string = response_bytes.decode('utf-8')\n",
    "\n",
    "        # print(\"Response String:\", response_string)  # Print the response for debugging purposes\n",
    "\n",
    "        try:\n",
    "            # Parse the JSON data\n",
    "            parsed_json = json.loads(response_string)\n",
    "            \n",
    "            # Access specific keys or values in the parsed JSON\n",
    "            output_prompt = parsed_json['output_prompt']\n",
    "\n",
    "            # Print the output prompt\n",
    "            # print(output_prompt)\n",
    "\n",
    "            bot_response = generate_response(response_string)\n",
    "            print(\"Bot:\", bot_response)\n",
    "\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(\"JSON Decode Error:\", e)\n",
    "            print(\"Invalid JSON received:\", response_string)\n",
    "            # Handle the error or debug accordingly\n",
    "\n",
    "# Start the conversation\n",
    "print(\"Start chatting with the bot ('quit' to exit):\")\n",
    "chat_with_bot()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
